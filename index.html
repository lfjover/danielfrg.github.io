<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <meta name="author" content="Daniel Rodriguez">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width">
        <title>Home | Daniel Rodriguez</title>

        <link rel="alternate" type="application/atom+xml" title="Daniel Rodriguez blog atom feed" href="/feeds/all.atom.xml" />
        <link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700' rel='stylesheet' type='text/css'>

        <link rel="stylesheet" href="//netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css">
        <link rel="stylesheet" href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css">
        <link rel="stylesheet" href="/theme/css/pygments.css">
        <link rel="stylesheet" href="/theme/css/main.css">

    </head>

    <body>
        <header class="main-header" style="background: url('/images/forest.jpg') no-repeat center center #DDD; background-size: 100%;">
        <nav>
            <div class="container">
            <ul>
                <li><a href="/" title="Home">Home</a></li>

                    <li><a href="/pages/about.html" title="About">About</a></li>
                    <li><a href="http://github.com/danielfrg" title="danielfrg's Github" rel="me">Github</a></li>
                    <li><a href="http://twitter.com/danielfrg" title="danielfrg Twitter" rel="me">Twitter</a></li>
                    <li><a href="/archives.html" title="Archive">Archives</a></li>
                    <li><a href="/feeds/all.atom.xml" title="danielfrg.github.io RSS feed" rel="me">RSS</a></li>
            </ul>
            </div>
        </nav>
        </header>

<div class="container index">

  <article>
    <header>
      <h2><a href="/blog/2013/11/27/ipython-notebook-aws-salt/">One-liner: Deploy python scipy stack with IPython notebook on AWS</a></h2>
      <time datetime="" title="2013-11-27T00:00:00" pubdate>November 27, 2013</time>
    </header>

    <div class="article_content">
      <p><strong>Problem:</strong> How many times have you needed to create a powerful EC2 instance with the the python scientific stack
installed and the ipython notebook running? I have to do this at least 2 or 3 times every week.</p>
<p>A simple solution is to have an AMI with all the libraries ready and create a new instance every time,
you can even have the ipython notebook as an upstart service in ubuntu so it runs when the instance is ready.
That was my previous solution, but that was before I learned <a href="http://saltstack.com/">salt</a>.</p>
<p>The problem with the AMI solution is that it gets dated really quickly and while update it is not hard, it is
annoying. Also having to login into AWS, look for the AMI and spin up and instance is annoying.</p>
<p><strong>Solution:</strong> <a href="http://saltstack.com/">Salt</a> + <a href="http://continuum.io/downloads">Anaconda</a> + <a href="http://www.vagrantup.com/">Vagrant</a></p>
<p>Salt will do the provisioning of the instance using states, that makes the updates of ...</p>
    </div>

    <div class="meta">
      <div>
        <a href="/blog/2013/11/27/ipython-notebook-aws-salt/" class="read_more">Read more &#8594;</a>
      </div>

      <div>
            <a href="/tag/python.html" class="tag">python</a>
            <a href="/tag/aws.html" class="tag">aws</a>
            <a href="/tag/salt.html" class="tag">salt</a>
            <a href="/tag/ipython-notebook.html" class="tag">ipython-notebook</a>
      </div>

    </div>

  </article>
  <div class="separator">&equiv;</div>
  <article>
    <header>
      <h2><a href="/blog/2013/11/23/harvard-ds/">Review: Harvard Data Science - Fall 2013</a></h2>
      <time datetime="" title="2013-11-23T00:00:00" pubdate>November 23, 2013</time>
    </header>

    <div class="article_content">
      <p>A few weeks/months ago I found on HackerNews that Harvard was publishing all their <a href="http://cs109.org/">Data Science course content</a> (lectures, videos, labs, homeworks) online. I couldn't miss the opportunity to find what are they teaching, it was a nice experience to see how much I have learned and what else I am missing. Also, when I saw that everything was on python I knew they are doing it right!</p>
<p>The homeworks are IPython notebooks, the books are what I consider every Data Scientist should read: <a href="http://shop.oreilly.com/product/0636920023784.do">Python for Data Analysis</a>, <a href="http://shop.oreilly.com/product/0636920018483.do">Machine Learning for Hackers</a>, <a href="http://nbviewer.ipython.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Prologue/Prologue.ipynb">Probabilistic Programming and Bayesian methods for Hackers</a>.</p>
<p>The homeworks were amazing and useful, I haven't seen all the videos (yet) but the ones I did were amazing. Below I do a little review of each homework, the stuff I learned and stuff that I think should be different.</p>
<p>Initially I wanted to use this opportunity ...</p>
    </div>

    <div class="meta">
      <div>
        <a href="/blog/2013/11/23/harvard-ds/" class="read_more">Read more &#8594;</a>
      </div>

      <div>
            <a href="/tag/python.html" class="tag">python</a>
            <a href="/tag/data-science.html" class="tag">data science</a>
            <a href="/tag/nlp.html" class="tag">NLP</a>
            <a href="/tag/statistics.html" class="tag">statistics</a>
            <a href="/tag/bayesian.html" class="tag">Bayesian</a>
            <a href="/tag/graphs.html" class="tag">graphs</a>
      </div>

    </div>

  </article>
  <div class="separator">&equiv;</div>
  <article>
    <header>
      <h2><a href="/blog/2013/10/31/month-log/">Month-Log.oct.2013</a></h2>
      <time datetime="" title="2013-10-31T00:00:00" pubdate>October 31, 2013</time>
    </header>

    <div class="article_content">
      <p>I've been busy with real work to write any specific posts for the blog but I realize it was
a productive month. I worked a lot and learned quite a few things and  new technologies and
I have some thoughts about them, I usually use twitter to share simple thoughts but they usually get
lost on the noise.</p>
<p>So I am going to start a monthly series in which I discuss a little bit about what I have done that month.
Hopefully mixing with regular posts I am hoping that this makes me learn more and more stuff every month so I have something to write about. On this case is October and a few weeks of September.</p>
<h2>Books I read</h2>
<p>I had to do some <a href="http://pig.apache.org/">pig</a> for my job so I used this opportunity to
consolidate a little bit my knowledge.
I had worked with pig a little ...</p>
    </div>

    <div class="meta">
      <div>
        <a href="/blog/2013/10/31/month-log/" class="read_more">Read more &#8594;</a>
      </div>

      <div>
            <a href="/tag/month-log.html" class="tag">month-log</a>
            <a href="/tag/python.html" class="tag">python</a>
            <a href="/tag/pig.html" class="tag">pig</a>
            <a href="/tag/nutch.html" class="tag">nutch</a>
            <a href="/tag/crawling.html" class="tag">crawling</a>
            <a href="/tag/vagrant.html" class="tag">vagrant</a>
            <a href="/tag/salt.html" class="tag">salt</a>
            <a href="/tag/luigi.html" class="tag">luigi</a>
      </div>

    </div>

  </article>
  <div class="separator">&equiv;</div>
  <article>
    <header>
      <h2><a href="/blog/2013/09/21/word2vec-yhat/">word2vec in yhat: Word vector similarity</a></h2>
      <time datetime="" title="2013-09-21T00:00:00" pubdate>September 21, 2013</time>
    </header>

    <div class="article_content">
      <p>A <a href="http://google-opensource.blogspot.com/2013/08/learning-meaning-behind-words.html">few weeks ago</a>
Google released some code to convert words to vectors called
<a href="https://code.google.com/p/word2vec/">word2vec</a>.
The company I am currently working on does something similar and I was quite amazed by the performance
and accuracy of Google's algorithm so I created a simple python wrapper to call the C code for training
and read the training vectors into numpy arrays, you can check it out on
<a href="https://pypi.python.org/pypi/word2vec">pypi (word2vec)</a>.</p>
<p>At the same time I found out about <a href="http://yhathq.com/">yhat</a>, I found about them
via twitter and after reading their blog I had to try their product. What they do is very simple
but very useful: take some python (scikit-learn) or R classifier and create a REST
endpoint to make predictions on new data. The product is still in very beta but the guys were
very responsive and they helped me to solve some of my issues.</p>
<p>The only restriction I had ...</p>
    </div>

    <div class="meta">
      <div>
        <a href="/blog/2013/09/21/word2vec-yhat/" class="read_more">Read more &#8594;</a>
      </div>

      <div>
            <a href="/tag/python.html" class="tag">python</a>
            <a href="/tag/word2vec.html" class="tag">word2vec</a>
            <a href="/tag/yhat.html" class="tag">yhat</a>
            <a href="/tag/machine-learning.html" class="tag">machine learning</a>
      </div>

    </div>

  </article>
  <div class="separator">&equiv;</div>
  <article>
    <header>
      <h2><a href="/blog/2013/09/11/django-celery-readability-crawler/">Django + Celery + Readability = Python relevant content crawler</a></h2>
      <time datetime="" title="2013-09-11T00:00:00" pubdate>September 11, 2013</time>
    </header>

    <div class="article_content">
      <p>I have written a <a href="/blog/2013/08/20/relevant-content-blog-crawler/">few</a> <a href="/blog/2013/04/01/nba-scraping-data/">posts</a>
about crawling content from the web. Mainly because I know the power of data
and the biggest data source in the world is the web, Google knew it and we all now how they are
doing. In my <a href="/blog/2013/08/20/relevant-content-blog-crawler/">last post</a> I wrote about crawling relevant content
from blogs; It worked but what if I want an admin UI to control the crawling. What if I just put
the crawler in an EC2 instance and just call it when I need to crawl.</p>
<p>The solution was pretty simple thanks to some python projects.
I just needed to move from <a href="http://www.sqlalchemy.org/">sqlalchemy</a> to
<a href="https://docs.djangoproject.com/en/1.5/">django</a> ORM, create a few <a href="http://celeryproject.org/">celery</a> tasks
and use <a href="https://github.com/celery/django-celery/">django-celery</a> to have a pretty UI of the tasks.</p>
<p>I was amazed on how easy it was to integrate celery with django. I just created a few tasks to
actually crawl blogs (I already had ...</p>
    </div>

    <div class="meta">
      <div>
        <a href="/blog/2013/09/11/django-celery-readability-crawler/" class="read_more">Read more &#8594;</a>
      </div>

      <div>
            <a href="/tag/python.html" class="tag">python</a>
            <a href="/tag/django.html" class="tag">django</a>
            <a href="/tag/celery.html" class="tag">celery</a>
            <a href="/tag/readability.html" class="tag">readability</a>
            <a href="/tag/crawling.html" class="tag">crawling</a>
      </div>

    </div>

  </article>
  <div class="separator">&equiv;</div>
  <article>
    <header>
      <h2><a href="/blog/2013/08/20/relevant-content-blog-crawler/">Relevant content blog crawler</a></h2>
      <time datetime="" title="2013-08-20T00:00:00" pubdate>August 20, 2013</time>
    </header>

    <div class="article_content">
      
<div class="text_cell_render border-box-sizing rendered_html">
<p>We all know that the most important aspect of data science or machine learning is data; with enough quality data you can do everything. Is also not a mistery that the problem of big data is to get that amount of data into a queryable, reportable or undestandable format; now we have a lot of amazing new tools to store that amount of data (casandra, hbase and more) but I still believe that almost nothing beats the fact of collecting a good amount (not necessarily huge, but the more you have the better) but structured data, and there is nothing more structured than SQL.</p>
<p>There is a lot of information power in the web and crawl it gives you that power (or is at least the first step), Google does it and I am pretty sure I don't have to say more. I cannot even begin to imagine the amount of work that they do to understand that data. So I created my own mini crawler to crawl what I call relevant content of websites, more specificly blogs, yes I believe blogs and not twitter have a lot of information power, that is why I am writing this in a blog.</p>...
    </div>

    <div class="meta">
      <div>
        <a href="/blog/2013/08/20/relevant-content-blog-crawler/" class="read_more">Read more &#8594;</a>
      </div>

      <div>
            <a href="/tag/python.html" class="tag">python</a>
            <a href="/tag/crawling.html" class="tag">crawling</a>
            <a href="/tag/beautifulsoup.html" class="tag">beautifulsoup</a>
            <a href="/tag/readability.html" class="tag">readability</a>
      </div>

    </div>

  </article>
  <div class="separator">&equiv;</div>
  <article>
    <header>
      <h2><a href="/blog/2013/07/27/not-so-basic-neural-network-python/">A not so basic neural network on python</a></h2>
      <time datetime="" title="2013-07-27T00:00:00" pubdate>July 27, 2013</time>
    </header>

    <div class="article_content">
      
<div class="text_cell_render border-box-sizing rendered_html">
<p>My <a href="http://danielfrg.github.io/blog/2013/07/03/basic-neural-network-python/">previous post</a> on implementing a basic Neural Network on python got a lot of attention staying one whole day on HN front page. I was very happy about that but more about the <a href="https://news.ycombinator.com/item?id=5994851">feedback</a> I got. The community gave me a lot of tips and tricks on how to improve. So now I am presenting an improved version which supports multiple hidden layers, more optimization options using minibatches and a more maintainable/understandable code (or so I believe).</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>I kept reading a lot about Neural Networks mainly by watching some videos from <a href="https://class.coursera.org/neuralnets-2012-001/class/index">Geoffrey's Hinton Neural Network course</a> on coursera. Also reading more on <a href="http://deeplearning.net/tutorial/">deeplearning.net</a> and trying to read some papers. That last task was definitely the hardest one because of the complexity of the papers. If I cannot even read them I can just imagine how hard is to write them.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>About the Neural networks course I didn't like it as much as the Machine Learning course. The main reason is that I had to watch most videos 3 or 4 times before understanding (something). This is definitely my fault because the material is great but it focuses more on the theory (math) which I am not that good at and not on the implementation which I am more interested. But I take it as a learning experience and I will try to finish those videos.</p>...
    </div>

    <div class="meta">
      <div>
        <a href="/blog/2013/07/27/not-so-basic-neural-network-python/" class="read_more">Read more &#8594;</a>
      </div>

      <div>
            <a href="/tag/python.html" class="tag">python</a>
            <a href="/tag/machine-learning.html" class="tag">machine learning</a>
            <a href="/tag/neural-networks.html" class="tag">neural networks</a>
      </div>

    </div>

  </article>
  <div class="separator">&equiv;</div>
  <article>
    <header>
      <h2><a href="/blog/2013/07/03/basic-neural-network-python/">Basic [1 hidden layer] neural network on Python</a></h2>
      <time datetime="" title="2013-07-03T00:00:00" pubdate>July 03, 2013</time>
    </header>

    <div class="article_content">
      
<div class="text_cell_render border-box-sizing rendered_html">
<p>Is really difficult be part of the data science / machine learning community and have not heard about Deep Neural Networks, everybody is talking about them. Is even harder for a person like me without a PhD and without a deep computer science or mathematics education to learn about them, because 1. Machine learning uses a quite heavy math and 2. There are no Neural Networks on sklearn.</p>
<p>Libraries like <a href="http://scikit-learn.org/dev/index.html">sklearn</a> hide all the stuff and let you use machine learning and get amazing results. But sometimes you need more, and also understanding how an algorithm is implemented can help you understand how to improve results. The learning curve is hard, you can easily spend hours on <a href="http://deeplearning.net/tutorial/">DeepLearning.net</a> and not understand anything. But there is hope.</p>
<p>I took Andrew's Ng <a href="https://www.coursera.org/course/ml">Machine Learning course</a> on Coursera wanting to get a better undesrtanding of how the algorithms I use almost everyday work. I learned a lot of usefull tricks and learned a lot more about simple machine learning implementations. Is important to start with the easy stuff or you get overwhelmed easy and eventually give up. Hopefully in a few more weeks I would be able to understand two or three more words on <a href="http://deeplearning.net/tutorial/">DeepLearning.net</a>...
    </div>

    <div class="meta">
      <div>
        <a href="/blog/2013/07/03/basic-neural-network-python/" class="read_more">Read more &#8594;</a>
      </div>

      <div>
            <a href="/tag/python.html" class="tag">python</a>
            <a href="/tag/machine-learning.html" class="tag">machine learning</a>
            <a href="/tag/neural-networks.html" class="tag">neural networks</a>
      </div>

    </div>

  </article>
  <div class="separator">&equiv;</div>
  <article>
    <header>
      <h2><a href="/blog/2013/04/01/nba-scraping-data/">Extracting NBA data from ESPN</a></h2>
      <time datetime="" title="2013-04-01T00:00:00" pubdate>April 01, 2013</time>
    </header>

    <div class="article_content">
      <p>I've been wanting to play with some sports data for a while. Today I decide to
stop procastinating and do it. The problems was that after searching a
while (15 minutes) for some data I was unable to find the data I wanted.
Even in the <a href="http://www.databasebasketball.com/">Basktetball Database</a>
(not really sure I undestand the site).</p>
<p>A friend showed me the <a href="http://espn.go.com/nba/">ESPN</a> stats and ask me if I
knew how to scrap the data from a website. I lied and told him Yes.
But I know python and its magic powers so after reading 15 minutes I knew how to do it.</p>
<p>I used <a href="http://docs.python-requests.org/en/latest/">requests</a> and
<a href="http://www.crummy.com/software/BeautifulSoup/">beautifulsoup</a> to download and
scrap the data from the ESPN site. Then used <a href="http://pandas.pydata.org/">pandas</a>
to order, slice, and save the data into simple csv files. Also used
<a href="http://ipython.org/">iPython notebooks</a> to develop the code faster.
And a little bit of my <a href="https://github.com/danielfrg/copper">copper</a>
project to use ...</p>
    </div>

    <div class="meta">
      <div>
        <a href="/blog/2013/04/01/nba-scraping-data/" class="read_more">Read more &#8594;</a>
      </div>

      <div>
            <a href="/tag/python.html" class="tag">python</a>
            <a href="/tag/crawling.html" class="tag">crawling</a>
            <a href="/tag/pandas.html" class="tag">pandas</a>
            <a href="/tag/requests.html" class="tag">requests</a>
            <a href="/tag/beautifulsoup.html" class="tag">beautifulsoup</a>
      </div>

    </div>

  </article>
  <div class="separator">&equiv;</div>
  <article>
    <header>
      <h2><a href="/blog/2013/03/08/pelican-ipython-notebook-plugin/">Plugin for blogging with iPython notebooks in Pelican</a></h2>
      <time datetime="" title="2013-03-08T00:00:00" pubdate>March 08, 2013</time>
    </header>

    <div class="article_content">
      <p>This is just a little update on my previous post about <a href="/blog/2013/02/16/blogging-pelican-ipython-notebook/">Blogging with iPython notebooks with pelican</a>.</p>
<p>One of the people behind pelican helped me to convert the <a href="/blog/2013/02/16/blogging-pelican-ipython-notebook/">previous code</a> to a pelican plugin and I just made it available via github: <a href="https://github.com/danielfrg/pelican-ipythonnb">pelican-ipythonnb</a>.</p>
<p>The only thing that changed is the installation but the docs on how to use it is below (or in the readme of the repo).</p>
<p>An example is my last post about a <a href="/blog/2013/03/07/kaggle-bulldozers-basic-cleaning/">cleaning data for a Kaggle competition</a>.</p>
<p>Happy blogging!</p>
<h2>Installation</h2>
<p>Download plugin files: <code>plugin/ipythonnb.py</code> and the <code>plugin/nbconverter</code> directory.</p>
<p>The esiest way is to locate the pelican directory (for example: <code>~/.virtualenvs/blog/lib/python2.7/site-packages/pelican/</code>) and paste plugins files in the <code>pelican/plugins</code> folder.
Then in the <code>pelicanconf.py</code> put: <code>PLUGINS = ['pelican.plugins.ipythonnb']</code>.</p>
<p>But is also is possible to add plugins on the same directory of the pelican project:
Create ...</p>
    </div>

    <div class="meta">
      <div>
        <a href="/blog/2013/03/08/pelican-ipython-notebook-plugin/" class="read_more">Read more &#8594;</a>
      </div>

      <div>
            <a href="/tag/python.html" class="tag">python</a>
            <a href="/tag/pelican.html" class="tag">pelican</a>
      </div>

    </div>

  </article>
  <div class="separator">&equiv;</div>

  <nav class="pagination row">
    <div class="col-md-6 left">
        <a class="prev" href="/index2.html">&#8592; Past</a>
    </div>
    <div class="col-md-6 right">
    </div>
  </nav>

  </div>

</div>



<script type="text/javascript">
var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-35523657-2']);
_gaq.push(['_trackPageview']);

(function() {
var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})();
</script>

    </body>
</html>