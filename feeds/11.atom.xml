<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Daniel Rodriguez</title><link href="/" rel="alternate"></link><link href="/feeds/11.atom.xml" rel="self"></link><id>/</id><updated>2013-11-27T00:00:00+00:00</updated><entry><title>One-liner: Deploy python scipy stack with IPython notebook on AWS</title><link href="/blog/2013/11/27/ipython-notebook-aws-salt/" rel="alternate"></link><updated>2013-11-27T00:00:00+00:00</updated><author><name>Daniel Rodriguez</name></author><id>tag:,2013-11-27:blog/2013/11/27/ipython-notebook-aws-salt/</id><summary type="html">&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; How many times have you needed to create a powerful EC2 instance with the the python scientific stack
installed and the ipython notebook running? I have to do this at least 2 or 3 times every week.&lt;/p&gt;
&lt;p&gt;A simple solution is to have an AMI with all the libraries ready and create a new instance every time,
you can even have the ipython notebook as an upstart service in ubuntu so it runs when the instance is ready.
That was my previous solution, but that was before I learned &lt;a href="http://saltstack.com/"&gt;salt&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The problem with the AMI solution is that it gets dated really quickly and while update it is not hard, it is
annoying. Also having to login into AWS, look for the AMI and spin up and instance is annoying.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; &lt;a href="http://saltstack.com/"&gt;Salt&lt;/a&gt; + &lt;a href="http://continuum.io/downloads"&gt;Anaconda&lt;/a&gt; + &lt;a href="http://www.vagrantup.com/"&gt;Vagrant&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Salt will do the provisioning of the instance using states, that makes the updates of new instances simple as changing a YAML file.
Anaconda is the best python scientific distribution I have found and the conda package manager is the perfect solution to install the scientific libraries, I don't want to compile numpy and scipy every time I create the instances, that takes at least 30 minutes.
Vagrant is used to create the instance and provision it with salt using one command.&lt;/p&gt;
&lt;p&gt;Install conda using a salt states is pretty easy because salt has support for pip, and conda is pip
installable (you have to run &lt;code&gt;conda init&lt;/code&gt; after &lt;code&gt;pip install conda&lt;/code&gt;) so is as simple as:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="l-Scalar-Plain"&gt;pip-packages&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
  &lt;span class="l-Scalar-Plain"&gt;pip.installed&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;user&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;root&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;names&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
      &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;conda&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;require&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
      &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;pkg&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;python-dev&lt;/span&gt;
      &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;pkg&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;python-pip&lt;/span&gt;

&lt;span class="l-Scalar-Plain"&gt;conda-check&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
  &lt;span class="l-Scalar-Plain"&gt;cmd.run&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;user&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;ubuntu&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;name&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;[&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;-d&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;/usr/conda-meta&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;]&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;echo&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;#39;changed=no&amp;#39;&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;||&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;echo&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;#39;changed=yes&amp;#39;&amp;quot;&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;stateful&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;True&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;require&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
      &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;pip&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;conda&lt;/span&gt;

&lt;span class="c1"&gt;# This will create some files into /usr, needs root&lt;/span&gt;
&lt;span class="l-Scalar-Plain"&gt;conda-init&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
  &lt;span class="l-Scalar-Plain"&gt;cmd.wait&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;user&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;root&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;name&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;conda&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;init&amp;quot;&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;watch&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
        &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;cmd&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;conda-check&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The main issue was that salt didn't have support for conda, so I &lt;a href="http://github.com/danielfrg/salt-conda/blob/master/conda.py"&gt;wrote my first salt module&lt;/a&gt; to manage conda virtual environments using salt.
The code below will create a conda virtual env and
install the ipython-notebook, numpy, scipy and pandas libraries using the conda repository
also will install luigi (or any other python library you want) using regular pip.
All of this will be inside the conda virtual env, because you &lt;strong&gt;should&lt;/strong&gt; use virtual envs.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="l-Scalar-Plain"&gt;venv&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
  &lt;span class="l-Scalar-Plain"&gt;conda.managed&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;user&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;ubuntu&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;pkgs&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;ipython-notebook,numpy,scipy,pandas,scikit-learn&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;require&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
      &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;cmd&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;conda-init&lt;/span&gt;

&lt;span class="l-Scalar-Plain"&gt;venv-pip&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
  &lt;span class="l-Scalar-Plain"&gt;pip.installed&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;user&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;ubuntu&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;names&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
      &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;luigi&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;bin_env&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;/home/ubuntu/envs/venv/bin/pip&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;require&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
      &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;conda&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;venv&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I created another module to start the ipython notebook in the background since salt does not support this natively, the state looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="l-Scalar-Plain"&gt;/home/vagrant/nbserver.pid&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
  &lt;span class="l-Scalar-Plain"&gt;nbserver.start_server&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;ip&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;0.0.0.0&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;port&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;80&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;nb_dir&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;/home/ubuntu/notebooks&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;require&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
      &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;conda&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;venv&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The final peace of the puzzle is how to spin up the instance quickly, Vagrant with the AWS provider is the solution.&lt;/p&gt;
&lt;p&gt;Vagrant is mainly used for development, and I use it to develop this solution but it also has a nice
integration with AWS, so on the &lt;code&gt;Vagrantfile&lt;/code&gt; you only need to change the AWS credentials and the
instance configuration.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="no"&gt;Vagrant&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;configure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="no"&gt;VAGRANTFILE_API_VERSION&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;
  &lt;span class="c1"&gt;# AWS Provider&lt;/span&gt;
  &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;provider&lt;/span&gt; &lt;span class="ss"&gt;:aws&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;aws&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;override&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;
    &lt;span class="n"&gt;aws&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;access_key_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;aws&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;secret_access_key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;aws&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keypair_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;daniel_keypair&amp;quot;&lt;/span&gt;

    &lt;span class="n"&gt;aws&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;security_groups&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;default&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;aws&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;instance_type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;c3.xlarge&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;aws&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;availability_zone&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;us-east-a&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;aws&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ami&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ami-a73264ce&amp;quot;&lt;/span&gt;  &lt;span class="c1"&gt;# Precise 12.04 64 bits&lt;/span&gt;

    &lt;span class="n"&gt;override&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;box&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;dummy&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;override&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ssh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;username&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ubuntu&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;override&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ssh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;private_key_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;~/.ssh/my_keypair.pem&amp;quot;&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;How you only need to run &lt;code&gt;vagrant up --provider aws&lt;/code&gt; and it will create an instance and provision it
with salt. Then just go to the URL of the EC2 instance and the notebook will be running in port 80.&lt;/p&gt;
&lt;p&gt;NOTE: Be sure to use a security group with port 22 and 80 open&lt;/p&gt;
&lt;p&gt;There are more things you can configure for your notebook such as passwords and more security, take a look &lt;a href="https://gist.github.com/iamatypeofwalrus/5183133"&gt;here&lt;/a&gt;. Also there are more solutions available
such as &lt;a href="https://www.wakari.io/"&gt;Continnums Wakari&lt;/a&gt; that I personally think is an overkill, I am sure is perfect for some people but not for me.&lt;/p&gt;
&lt;p&gt;This solution gives you the notebook up and running in two minutes, and if you need more control on the instance you can just SSH to it and do whatever you want. Also you only pay the Amazon fees, so for my personal needs is the perfect solution.&lt;/p&gt;
&lt;p&gt;The whole code is on github: &lt;a href="https://github.com/danielfrg/salt-conda"&gt;salt conda module&lt;/a&gt;, look in &lt;code&gt;example/ipythonnb&lt;/code&gt;&lt;/p&gt;</summary><category term="python"></category><category term="aws"></category><category term="salt"></category><category term="ipython-notebook"></category></entry><entry><title>Review: Harvard Data Science - Fall 2013</title><link href="/blog/2013/11/23/harvard-ds/" rel="alternate"></link><updated>2013-11-23T00:00:00+00:00</updated><author><name>Daniel Rodriguez</name></author><id>tag:,2013-11-23:blog/2013/11/23/harvard-ds/</id><summary type="html">&lt;p&gt;A few weeks/months ago I found on HackerNews that Harvard was publishing all their &lt;a href="http://cs109.org/"&gt;Data Science course content&lt;/a&gt; (lectures, videos, labs, homeworks) online. I couldn't miss the opportunity to find what are they teaching, it was a nice experience to see how much I have learned and what else I am missing. Also, when I saw that everything was on python I knew they are doing it right!&lt;/p&gt;
&lt;p&gt;The homeworks are IPython notebooks, the books are what I consider every Data Scientist should read: &lt;a href="http://shop.oreilly.com/product/0636920023784.do"&gt;Python for Data Analysis&lt;/a&gt;, &lt;a href="http://shop.oreilly.com/product/0636920018483.do"&gt;Machine Learning for Hackers&lt;/a&gt;, &lt;a href="http://nbviewer.ipython.org/urls/raw.github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/master/Prologue/Prologue.ipynb"&gt;Probabilistic Programming and Bayesian methods for Hackers&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The homeworks were amazing and useful, I haven't seen all the videos (yet) but the ones I did were amazing. Below I do a little review of each homework, the stuff I learned and stuff that I think should be different.&lt;/p&gt;
&lt;p&gt;Initially I wanted to use this opportunity to get into &lt;a href="http://julialang.org/"&gt;Julia&lt;/a&gt;, but the amount of libraries that are available on python and not on Julia was to high for me to drive me back into python (once again).&lt;/p&gt;
&lt;h2&gt;Homework 0&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://nbviewer.ipython.org/urls/raw.github.com/danielfrg/harvard-cs109-fall-2013/master/homeworks/HW0/HW0_mysolution.ipynb"&gt;My solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Basic introduction to python and some of it scientific libraries.&lt;/p&gt;
&lt;p&gt;Things I changed:
Use beautifulsoup4 instead of 3, not sure why they decided to go with an deprecated version.&lt;/p&gt;
&lt;h2&gt;Homework 1&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://nbviewer.ipython.org/urls/raw.github.com/danielfrg/harvard-cs109-fall-2013/master/homeworks/HW1/HW1_mysolution.ipynb"&gt;My solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The main idea was to scrape data from the web, in my opinion one of the most important things a Data Scientist can do is to grab its own data, it gives a big boost to analysis if the person responsible for the analysis decides upfront what data is needed. Is doesn't need to be perfect at first, but usually helps &lt;strong&gt;a lot&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The final problem shows the properties of bootstrapping, a must know. Also some simple problems to get started with matplotlib.&lt;/p&gt;
&lt;p&gt;I knew about &lt;a href="http://www.clips.ua.ac.be/pattern"&gt;pattern&lt;/a&gt; but never had the chance to play with it. I learned that includes a xml/html parser that creates a DOM so one can access the different fields/tags, I usually use &lt;a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/"&gt;beautifulsoup&lt;/a&gt; for html and &lt;a href="http://lxml.de/"&gt;lxml&lt;/a&gt; for xml but is nice to have an alternative.&lt;/p&gt;
&lt;p&gt;I had no idea about &lt;a href="http://docs.python.org/2/library/fnmatch.html"&gt;fnmatch&lt;/a&gt;, I always used regular expressions but I think that for simple matching tasks I am going to use fnmatch from now own and hopefully will save me some time.&lt;/p&gt;
&lt;h2&gt;Homework 2&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://nbviewer.ipython.org/urls/raw.github.com/danielfrg/harvard-cs109-fall-2013/master/homeworks/HW2/HW2_mysolution.ipynb"&gt;My solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A basic introduction to statistical models by doing a predictions the Obama campaign, very interesting exercise. I felt like Nate Silver and it was kind of the idea, show that is possible to do a simple but useful prediction doing a reasonable amount of work. As with a lot of work with data usually the 80% gets done in 20% of the time but the remaining 20% takes the remaining 80% of the time.&lt;/p&gt;
&lt;p&gt;What I changed:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Used scipy.stats for probability calculations instead of doing those myself. DRY.&lt;/li&gt;
&lt;li&gt;I tried the new ggplot for python to do some of the plots faster, worked perfectly&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Homework 3&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://nbviewer.ipython.org/urls/raw.github.com/danielfrg/harvard-cs109-fall-2013/master/homeworks/HW3/HW3_mysolution.ipynb"&gt;My solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Interesting problem of making a simple prediction of movies reviews intro two categories (fresh or rotten).&lt;/p&gt;
&lt;p&gt;I liked the problem but I think it would be a good idea to use &lt;a href="http://nltk.org/"&gt;NLTK&lt;/a&gt; instead of hand writing some of the functions and doing a hand made classifier using scikit-learn. I realize that it is &lt;strong&gt;really&lt;/strong&gt; easy to do it using the Vectorizer and Naive Bayes classes and I had never done it before so it was a good learning experience, but an introduction to NLTK would be nice.&lt;/p&gt;
&lt;p&gt;The example is very easy to reproduce in NLTK as NLTKs author &lt;a href="http://streamhacker.com/2010/05/10/text-classification-sentiment-analysis-naive-bayes-classifier"&gt;showed in his blog&lt;/a&gt;. Is an old post but I was able to reproduce the results a few months ago and I was amazed by the results of a simple sentiment classifier. I believe the course missed an opportunity to teach this.&lt;/p&gt;
&lt;p&gt;I liked the cross-validation and specially the &lt;strong&gt;model calibration&lt;/strong&gt; sections. Also the rotten tomatoes API is a pretty good source of data.&lt;/p&gt;
&lt;h2&gt;Homework 4&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://nbviewer.ipython.org/urls/raw.github.com/danielfrg/harvard-cs109-fall-2013/master/homeworks/HW4/HW4_mysolution.ipynb"&gt;My solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For sure the most interesting homework. Not only a nice collaborative filtering problem (with some bayesian analysis) but also an introduction to MapReduce jobs on hadoop using MRJob. I never used MRJob before so it was nice to use it for the first time &lt;strong&gt;but&lt;/strong&gt; I don't think it will replace my love for  &lt;a href="https://github.com/spotify/luigi"&gt;luigi&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/spotify/luigi"&gt;Luigi&lt;/a&gt; is a nice and small library form the guys at spotify. It comes with hadoop support built in but at the same time can be extended to any kind of data jobs (e.g. postgres or simple text files). Since I found about luigi I have been writing a lot of code as pipelines and I could not be happier.&lt;/p&gt;
&lt;p&gt;MRJob killer feature is EMR support that luigi does not have currently. Another nice feature of MRJob is the first class documentation. Luigi on the other hand is limited to a Readme file and you will have to read the source code to discover some features, but it is worth it.&lt;/p&gt;
&lt;p&gt;I have to say that MRJob is very easy and to &lt;strong&gt;MapReduce only&lt;/strong&gt; jobs is the way to go, I highly recommend it.&lt;/p&gt;
&lt;p&gt;My knowledge about collaborative filtering was (and still is) &lt;strong&gt;very&lt;/strong&gt; limited so I only have to say that I loved to learn about it!&lt;/p&gt;
&lt;h2&gt;Homework 5&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://nbviewer.ipython.org/urls/raw.github.com/danielfrg/harvard-cs109-fall-2013/master/homeworks/HW5/HW5_mysolution.ipynb"&gt;My solution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Graphs was always that topic that for some reason I haven't dive into yet, but is definitely in my thing to learn list. So I took this opportunity to learn everything I could by watching the lectures and doing the homework.
I also grabbed a copy of &lt;a href="http://graphdatabases.com"&gt;graph databases by O'reilly&lt;/a&gt; from the university library and I am very exited about it, I am a little behind on my reading so it might take a while.&lt;/p&gt;
&lt;p&gt;The homework was about the congress and the relation between them. Nothing fancy but interesting.
Second homework that is about politics, I guess that the data is available but it would be nice to chose a different topic.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The objective of learning new stuff was accomplished. The course gave me perfect introduction to a variety of topics and I have more clear ideas on how to proceed from now own.&lt;/p&gt;
&lt;p&gt;I had a lot of fun doing the homeworks, I learned a lot of stuff I didn't knew before. The statistics sections were a little bit hard for me but that was the idea.  I felt really comfortable with a lot of the tools used so I know I am doing it right. Finally, now I know in what I need to focus more.&lt;/p&gt;
&lt;p&gt;The main conclusion I got is that there is still a lot to learn and the Data Science space keeps changing every day, that is the reason I like it: When I think I am good at something, I realize I am just getting started.&lt;/p&gt;
&lt;p&gt;Thanks to Harvard for publishing all the content online.&lt;/p&gt;</summary><category term="python"></category><category term="data science"></category><category term="NLP"></category><category term="statistics"></category><category term="Bayesian"></category><category term="graphs"></category></entry><entry><title>Using cloud9 to save computing power and to code from everywhere too</title><link href="/blog/2012/11/03/using-cloud9-to-save-computing-power-and-to-code-from-everywhere-too/" rel="alternate"></link><updated>2012-11-03T14:46:00+00:00</updated><author><name>Daniel Rodriguez</name></author><id>tag:,2012-11-03:blog/2012/11/03/using-cloud9-to-save-computing-power-and-to-code-from-everywhere-too/</id><summary type="html">&lt;p&gt;I am taking my second course on &lt;a href="https://www.coursera.org/" title="Coursera"&gt;Coursera&lt;/a&gt; Computational Investing -
Part 1; pretty fun so far. The homework 1 was to find a portfolio of 4
equities with the best (highest) Sharpe ratio from 2011. With a little
bit of coding in python I was able to download all SPY stocks and loop
through out the different combinations of them with different weights to
find the best portfolio. The problem I found was that my PC is to slow
for this task :(&lt;/p&gt;
&lt;p&gt;First I have to said I am not an algorithm expert so the process is
linear, but I was able to optimize a little bit the process by loading
into memory first all the data and some other little stuff that makes
the calculation faster; that is from 1 1/2 minutes initially to 30
seconds combining 5 stocks. And I was able to combine up to 8 stocks on
my PC without any problem but when I try to combine more than 8 well it
was so much for my PC; I even take a shower and the calculation wasn't
over, that is my limit :P&lt;/p&gt;
&lt;p&gt;There are solutions to make this type of calculation on the cloud such
as &lt;a href="http://www.picloud.com/" title="PiCloud"&gt;PiCloud&lt;/a&gt; a service that I am definitely going to try out soon but
I found &lt;a href="https://c9.io/" title="Cloud9"&gt;cloud9&lt;/a&gt; was a solution to this problem too.&lt;/p&gt;
&lt;p&gt;Cloud 9 says they are the Google Docs for code and they really are.
Initially I had my doubts about the online editor mainly because I love
&lt;a href="http://www.sublimetext.com/" title="Sublime Text"&gt;Sublime text&lt;/a&gt;, and yes it is not so powerful as sublime but is
&lt;strong&gt;very&lt;/strong&gt; good. But the features such the Github integration and the
online terminal sold me the service ;I test it and didn't disappoint me.&lt;/p&gt;
&lt;p&gt;I was able with one-click to clone the repository on my Github and run
the code on their infrastructure (powered by &lt;a href="https://openshift.redhat.com/app/" title="OpenShift"&gt;OpenShift&lt;/a&gt;) with no
problems at all. Just need to install the required libraries (&lt;a href="http://numpy.scipy.org/" title="numpy"&gt;numpy&lt;/a&gt;
- running&lt;em&gt;easy_install numpy&lt;/em&gt;) and then it was as simple as run &lt;em&gt;python
portfolio.py&lt;/em&gt; and see the code running much faster than on my PC.&lt;/p&gt;
&lt;p&gt;Also the ability to run the code and edit it from everywhere is amazing.
I was able to connect from my University and keep testing better
portfolios. On the image below I ran 83 iteration of the code in less
than 3 seconds, on my PC takes 20 seconds or more. The max number of
iterations I ran was up to 250k taking up to 8 minutes. And after
modifying the code I was able to push from Cloud9 directly to my Github
and back to my PC. Git makes the flow is very smooth and the terminal
from Cloud9 good enough for that and more.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Django UI" src="/images/blog/2012/11/cloud9/comp-investing-cloud9-google-chrome_001.png" title="Running code in the Cloud9 Terminal" /&gt;&lt;/p&gt;
&lt;p&gt;The service has some problems, sometimes the terminal goes crazy for no
reason (that I could find) and I had to refresh the page, but in general
works great.&lt;/p&gt;
&lt;p&gt;I found this a very easy way to execute code on the cloud saving
computing power and getting faster responses. Next I want to try
&lt;a href="http://www.picloud.com/" title="PiCloud"&gt;PiCloud&lt;/a&gt; and &lt;a href="https://openshift.redhat.com/app/" title="OpenShift"&gt;OpenShift&lt;/a&gt; directly.&lt;/p&gt;
&lt;p&gt;The code for the computational investing is on &lt;a href="https://github.com/dfrodriguez143/comp-investing" title="Computational Investing on Github "&gt;my Github&lt;/a&gt; if anyone
is interested, is going to be updated as the course goes through.&lt;/p&gt;</summary><category term="cloud9"></category><category term="computational investing"></category><category term="coursera"></category><category term="numpy"></category><category term="python"></category></entry></feed>