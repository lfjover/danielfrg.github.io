<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>A not so basic neural network on python | Daniel Rodriguez</title>
        <meta name="author" content="Daniel Rodriguez">
        <meta name="description" content="Blog is written by Daniel Rodriguez. He writes about coding, python, data science and his projects.">
        <meta name="viewport" content="width=device-width">

        <link rel="alternate" type="application/atom+xml" title="Daniel Rodriguez blog atom feed"
              href="/feeds/all.atom.xml" />

        <link rel="stylesheet" href="/theme/css/normalize.min.css">
        <link rel="stylesheet" href="/theme/css/fonts/proximanova.css">
        <link rel="stylesheet" href="/theme/css/fonts/ss-social.css">
        <link rel="stylesheet" href="/theme/css/fonts/ss-standard.css">
        <link rel="stylesheet" href="/theme/css/pygments.css">
        <link rel="stylesheet" href="/theme/css/ipython.css">
        <link rel="stylesheet" href="/theme/css/main.css">
    </head>
    <body>
        <div class="header">
            <div class="navbar">
              <a href="/" class="ss-icon" title="home">home</a>
              <a href="/tags.html" class="ss-icon" title="tags">tag</a>
              <a href="http://about.me/danielfrg" class="ss-icon" title="about">user</a>
              <a href="http://twitter.com/danielfrg" class="ss-icon ss-social" title="on twitter">twitter</a>
              <a href="http://github.com/danielfrg" class="ss-icon ss-social" title="on github">octocat</a>
              <a href="/feeds/all.atom.xml" class="ss-icon ss-social" title="email me">rss</a>
              <a href="mailto:df.rodriguez143@gmail.com" class="ss-icon" title="email me">mail</a>
            </div>
        </div>

        <div id="content">
            <div class="post">
    <article>
        <header>
            <h1>A not so basic neural network on python</h1>
        </header>
        <div class='post-content'>
            <div class="ipynb"><div class="text_cell_render border-box-sizing rendered_html">
<p>My <a href="http://danielfrg.github.io/blog/2013/07/03/basic-neural-network-python/">previous post</a> on implementing a basic Neural Network on python got a lot of attention staying one whole day on HN front page. I was very happy about that but more about the <a href="https://news.ycombinator.com/item?id=5994851">feedback</a> I got. The community gave me a lot of tips and tricks on how to improve. So now I am presenting an improved version which supports multiple hidden layers,  more optimization options using minibatches and a more maintainable/understandable code (or so I believe).</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>I kept reading a lot about Neural Networks mainly by watching some videos from <a href="https://class.coursera.org/neuralnets-2012-001/class/index">Geoffrey's Hinton Neural Network course</a> on coursera. Also reading more on <a href="http://deeplearning.net/tutorial/">deeplearning.net</a> and trying to read some papers. That last task was definitely the hardest one because of the complexity of the papers. If I cannot even read them I can just imagine how hard is to write them.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>About the Neural networks course I didn't like it as much as the Machine Learning course. The main reason is that I had to watch most videos 3 or 4 times before understanding (something). This is definitely my fault because the material is great but it focuses more on the theory (math) which I am not that good at and not on the implementation which I am more interested. But I take it as a learning experience and I will try to finish those videos.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Some people criticized (besides my orthography, sorry about my spanglish :P) that I didn't use any cross-validation and that the iris and digits examples are way to simple datasets. I agree that both things are necessary but I am not trying to make this post as a scientific paper with complete benchmarks of different optimization algorithms I leave that to the researchers who have spent years studying neural networks. But in on this case I am using the MNIST dataset to compare.</p>
<p>My objective was to learn about them and to have some personal implementation of the algorithm, just to say that I have done it :P</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h2 class="ipynb">
  Implementation
</h2>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>I was very tempted to use <a href="http://deeplearning.net/software/theano/">theano</a> and but at the end I decided to do a pure numpy implementation.</p>
<p>It is defenitly possible (and not that hard neither that easy) to create a theano implementation and I took some of the ideas from their site such as creating a class for each layer because it makes easier to combine and create different implementations and makes the code more mantainable. But other than the optimization I still cannot see the value of using theano, of course the speed up is important but I thing I prefer the <a href="http://numba.pydata.org/">Numba</a> approach.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>The implementation is very similar to the previous post, the differences are:</p>
<ol>
<li>Support for multiple hidden layers. I still train the network using a big 1d-array of weights because that allows to use the scipy optimizations.</li>
<li>A more "smart" random initialization for the arrays.</li>
<li>Support for mini-batch optimization, which is a must have with bigger datasets.</li>
<li>Created a Layer class which weights are mapped to slices of the big weight array that is optimized so they are sharing that part of memory. That allows to a more maintainable code and probably to include pre-training in a future.</li>
</ol>
<p>One feature that I think is nice is that when fitting one can actually interrupt (not restart) the ipython kernel and the last weights are going to be saved in the class (<code>NN.coef_</code>) so one doesn't have to start the training from nothing, also I added a callback on each epoch so one can for example see the score in a validation dataset.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3 class="ipynb">
  Basic classes and functions
</h3>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">optimize</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="k">class</span> <span class="nc">Layer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_in</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_out</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">random_state</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">rnd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">rnd</span> <span class="o">=</span> <span class="n">random_state</span>
        
        <span class="k">if</span> <span class="n">W</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">rnd</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_out</span><span class="p">,</span> <span class="n">n_in</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">W</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
        
    <span class="k">def</span> <span class="nf">output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">linear_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">linear_output</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="k">class</span> <span class="nc">SigmoidLayer</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_in</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_out</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">Layer</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_in</span><span class="p">,</span> <span class="n">n_out</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">random_state</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">sigmoid</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3 class="ipynb">
  Cost function and gradient
</h3>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="k">def</span> <span class="nf">unpack_weigths</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">weights_meta</span><span class="p">):</span>
    <span class="n">start_pos</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">weights_meta</span><span class="p">:</span>
        <span class="n">end_pos</span> <span class="o">=</span> <span class="n">start_pos</span> <span class="o">+</span> <span class="n">layer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">layer</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">yield</span> <span class="n">weights</span><span class="p">[</span><span class="n">start_pos</span><span class="p">:</span><span class="n">end_pos</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">layer</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">layer</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">start_pos</span> <span class="o">=</span> <span class="n">end_pos</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="k">def</span> <span class="nf">cost</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">weights_meta</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">):</span>
    <span class="c"># Forward</span>
    <span class="n">act_prev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">unpack_weigths</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">weights_meta</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">act_prev</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
        <span class="n">activation</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">act_prev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">activation</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">num_labels</span><span class="p">)[</span><span class="n">y</span><span class="p">]</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">activation</span>
    <span class="n">costPositive</span> <span class="o">=</span> <span class="o">-</span><span class="n">Y</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
    <span class="n">costNegative</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">Y</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">J</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">costPositive</span> <span class="o">-</span> <span class="n">costNegative</span><span class="p">)</span> <span class="o">/</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">J</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="k">def</span> <span class="nf">unpack_weigths_inv</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">weights_meta</span><span class="p">):</span>
    <span class="n">end_pos</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">weights_meta</span><span class="p">):</span>
        <span class="n">start_pos</span> <span class="o">=</span> <span class="n">end_pos</span> <span class="o">-</span> <span class="n">layer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">layer</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">yield</span> <span class="n">weights</span><span class="p">[</span><span class="n">start_pos</span><span class="p">:</span><span class="n">end_pos</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">layer</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">layer</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">end_pos</span> <span class="o">=</span> <span class="n">start_pos</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="k">def</span> <span class="nf">cost_prime</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">weights_meta</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">):</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">num_labels</span><span class="p">)[</span><span class="n">y</span><span class="p">]</span>
    <span class="n">Deltas</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">shape</span> <span class="ow">in</span> <span class="n">weights_meta</span><span class="p">]</span>
    
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
        <span class="c"># Forward</span>
        <span class="c">#row = np.array([row])</span>
        <span class="n">act_prev</span> <span class="o">=</span> <span class="n">row</span>
        <span class="n">activations</span> <span class="o">=</span> <span class="p">(</span><span class="n">act_prev</span><span class="p">,</span> <span class="p">)</span>
        <span class="k">for</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">unpack_weigths</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">weights_meta</span><span class="p">):</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">act_prev</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
            <span class="n">activation</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">act_prev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="p">)</span>
            <span class="n">activations</span> <span class="o">=</span> <span class="n">activations</span> <span class="o">+</span> <span class="p">(</span><span class="n">act_prev</span><span class="p">,</span> <span class="p">)</span>
        
        <span class="c"># Backprop</span>
        <span class="n">prev_delta</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span>  <span class="c"># last delta</span>
        <span class="n">deltas</span> <span class="o">=</span> <span class="p">(</span><span class="n">prev_delta</span><span class="p">,</span> <span class="p">)</span>  <span class="c"># deltas[0] == delta2</span>
        <span class="k">for</span> <span class="n">act</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">activations</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">unpack_weigths_inv</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">weights_meta</span><span class="p">)):</span>
            <span class="n">delta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">prev_delta</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">*</span> <span class="p">(</span><span class="n">act</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">act</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span><span class="o">.</span><span class="n">T</span>
            <span class="n">deltas</span> <span class="o">=</span> <span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="p">)</span> <span class="o">+</span> <span class="n">deltas</span>
            <span class="n">prev_delta</span> <span class="o">=</span> <span class="n">delta</span>

        <span class="c"># Accumulate errors</span>
        <span class="k">for</span> <span class="n">delta</span><span class="p">,</span> <span class="n">act</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">deltas</span><span class="p">,</span> <span class="n">activations</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Deltas</span><span class="p">))):</span>
            <span class="n">Deltas</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">Deltas</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">delta</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">act</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Deltas</span><span class="p">)):</span>
        <span class="n">Deltas</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">Deltas</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="nb">tuple</span><span class="p">([</span><span class="n">D</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">D</span> <span class="ow">in</span> <span class="n">Deltas</span><span class="p">]))</span>
</pre></div>

</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3 class="ipynb">
  Optimization
</h3>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>This class is simulating a <code>MinibatchOpti</code> module.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="k">class</span> <span class="nc">MinibatchOpti</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">minibatches</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">random_state</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">rnd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">()</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">random_state</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">rnd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
           <span class="n">rnd</span> <span class="o">=</span> <span class="n">random_state</span>

        <span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="k">if</span> <span class="n">batch_size</span> <span class="o">&gt;=</span> <span class="mi">1</span> <span class="k">else</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">m</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">))</span>
        <span class="n">max_batchs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">m</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">))</span>
        
        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="n">random_indices</span> <span class="o">=</span> <span class="n">rnd</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">m</span><span class="p">),</span> <span class="n">m</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_batchs</span><span class="p">):</span>
                <span class="n">batch_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">)</span>
                <span class="n">indices</span> <span class="o">=</span> <span class="n">random_indices</span><span class="p">[</span><span class="n">batch_indices</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="k">yield</span> <span class="n">X</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">yield</span> <span class="n">X</span><span class="p">[</span><span class="n">indices</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">GD</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">jac</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">()):</span>
        <span class="n">weights</span> <span class="o">-=</span> <span class="n">options</span><span class="p">[</span><span class="s">&#39;learning_rate&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">jac</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
        <span class="n">options</span><span class="p">[</span><span class="s">&#39;learning_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">options</span><span class="p">[</span><span class="s">&#39;learning_rate&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">options</span><span class="p">[</span><span class="s">&#39;learning_rate_decay&#39;</span><span class="p">]</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">GD_momentum</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">jac</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">()):</span>
        <span class="n">bigjump</span> <span class="o">=</span> <span class="n">options</span><span class="p">[</span><span class="s">&#39;momentum&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">options</span><span class="p">[</span><span class="s">&#39;step&#39;</span><span class="p">]</span>
        <span class="n">weights</span> <span class="o">-=</span> <span class="n">bigjump</span>
        <span class="n">correction</span> <span class="o">=</span> <span class="n">options</span><span class="p">[</span><span class="s">&#39;learning_rate&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">jac</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
        <span class="n">weights</span> <span class="o">-=</span> <span class="n">correction</span>
        <span class="n">options</span><span class="p">[</span><span class="s">&#39;step&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">bigjump</span> <span class="o">+</span> <span class="n">correction</span>
        <span class="n">options</span><span class="p">[</span><span class="s">&#39;learning_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">options</span><span class="p">[</span><span class="s">&#39;learning_rate&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">options</span><span class="p">[</span><span class="s">&#39;learning_rate_decay&#39;</span><span class="p">]</span>
        <span class="n">options</span><span class="p">[</span><span class="s">&#39;momentum&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">options</span><span class="p">[</span><span class="s">&#39;momemtum_decay&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">options</span><span class="p">[</span><span class="s">&#39;momentum&#39;</span><span class="p">]</span>
        
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">RMSPROP</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">jac</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">()):</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="n">jac</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
        <span class="n">options</span><span class="p">[</span><span class="s">&#39;moving_mean_squared&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">options</span><span class="p">[</span><span class="s">&#39;decay&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">options</span><span class="p">[</span><span class="s">&#39;moving_mean_squared&#39;</span><span class="p">]</span> \
                                         <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">options</span><span class="p">[</span><span class="s">&#39;decay&#39;</span><span class="p">])</span> <span class="o">*</span> <span class="n">gradient</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">weights</span> <span class="o">-=</span> <span class="n">gradient</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">options</span><span class="p">[</span><span class="s">&#39;moving_mean_squared&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>
        
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">CG</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">jac</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">()):</span>
        <span class="n">ans</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="n">jac</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">&#39;CG&#39;</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">args</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s">&#39;maxiter&#39;</span><span class="p">:</span> <span class="n">options</span><span class="p">[</span><span class="s">&#39;mb_maxiter&#39;</span><span class="p">]})</span>
        <span class="n">weights</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">ans</span><span class="o">.</span><span class="n">x</span>
        
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">LBFGSB</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">jac</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">()):</span>
        <span class="n">ans</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="n">jac</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s">&#39;L-BFGS-B&#39;</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">args</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s">&#39;maxiter&#39;</span><span class="p">:</span> <span class="n">options</span><span class="p">[</span><span class="s">&#39;mb_maxiter&#39;</span><span class="p">]})</span>
        <span class="n">weights</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">ans</span><span class="o">.</span><span class="n">x</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">minimize</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">jac</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                 <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&#39;GD&#39;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="s">&#39;learning_rate&#39;</span> <span class="ow">in</span> <span class="n">options</span><span class="p">,</span> <span class="s">&#39;GD needs a learning rate&#39;</span>
            <span class="k">if</span> <span class="s">&#39;learning_rate_decay&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">options</span><span class="p">:</span>
                <span class="n">options</span><span class="p">[</span><span class="s">&#39;learning_rate_decay&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="s">&#39;momentum&#39;</span> <span class="ow">in</span> <span class="n">options</span><span class="p">:</span>
                <span class="k">if</span> <span class="s">&#39;momemtum_decay&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">options</span><span class="p">:</span>
                    <span class="n">options</span><span class="p">[</span><span class="s">&#39;momemtum_decay&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="n">options</span><span class="p">[</span><span class="s">&#39;step&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">update</span> <span class="o">=</span> <span class="n">MinibatchOpti</span><span class="o">.</span><span class="n">GD_momentum</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">update</span> <span class="o">=</span> <span class="n">MinibatchOpti</span><span class="o">.</span><span class="n">GD</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&#39;RMSPROP&#39;</span><span class="p">:</span>
            <span class="n">options</span><span class="p">[</span><span class="s">&#39;moving_mean_squared&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">update</span> <span class="o">=</span> <span class="n">MinibatchOpti</span><span class="o">.</span><span class="n">RMSPROP</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&#39;CG&#39;</span><span class="p">:</span>
            <span class="n">update</span> <span class="o">=</span> <span class="n">MinibatchOpti</span><span class="o">.</span><span class="n">CG</span>
        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s">&#39;L-BFGS-B&#39;</span><span class="p">:</span>
            <span class="n">update</span> <span class="o">=</span> <span class="n">MinibatchOpti</span><span class="o">.</span><span class="n">LBFGSB</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&#39;Optimization method not found&#39;</span><span class="p">)</span>

        <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">prev_cost</span> <span class="o">=</span> <span class="mf">1e8</span>
        <span class="k">for</span> <span class="n">_X</span><span class="p">,</span> <span class="n">_y</span> <span class="ow">in</span> <span class="n">MinibatchOpti</span><span class="o">.</span><span class="n">minibatches</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">):</span>
            <span class="n">update</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">jac</span><span class="p">,</span> <span class="n">_X</span><span class="p">,</span> <span class="n">_y</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">)</span>
            <span class="n">new_cost</span> <span class="o">=</span> <span class="n">fun</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="n">new_cost</span> <span class="o">-</span> <span class="n">prev_cost</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">diff</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">print</span> <span class="s">&#39;Minimum tolerance reached in </span><span class="si">%i</span><span class="s"> iterations&#39;</span> <span class="o">%</span> <span class="n">i</span>
                <span class="k">break</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">maxiter</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;=</span> <span class="mi">1</span> <span class="p">:</span>
                    <span class="k">print</span> <span class="s">&#39;Maximum number of iterations reached&#39;</span>
                <span class="k">break</span>
            <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">print</span> <span class="n">i</span><span class="p">,</span> <span class="n">newJ</span>    
            <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">stop</span> <span class="o">=</span> <span class="n">callback</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">stop</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
                    <span class="k">break</span>
            <span class="n">prev_cost</span> <span class="o">=</span> <span class="n">new_cost</span>
            <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
</pre></div>

</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3 class="ipynb">
  The sklearn-stlye class
</h3>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="k">class</span> <span class="nc">NN</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_layers</span><span class="p">,</span> <span class="n">coef0</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                 <span class="n">opti_method</span><span class="o">=</span><span class="s">&#39;GD&#39;</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                 <span class="n">opti_options</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layers</span> <span class="o">=</span> <span class="n">hidden_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="bp">None</span> <span class="k">if</span> <span class="n">coef0</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">coef0</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">random_state</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rnd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">()</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">random_state</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rnd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rnd</span> <span class="o">=</span> <span class="n">random_state</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">opti_method</span> <span class="o">=</span> <span class="n">opti_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maxiter</span> <span class="o">=</span> <span class="n">maxiter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">opti_options</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">opti_options</span> <span class="ow">is</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">opti_options</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback</span> <span class="o">=</span> <span class="n">callback</span>
        
    <span class="k">def</span> <span class="nf">rand_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights_info</span><span class="p">,</span> <span class="n">random_state</span><span class="p">):</span>
        <span class="n">w_sizes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">layer_info</span> <span class="ow">in</span> <span class="n">weights_info</span><span class="p">:</span>
            <span class="n">w_sizes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer_info</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">layer_info</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">ans</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">w_sizes</span><span class="p">))</span>
        
        <span class="c"># &quot;Smart&quot; random initialization</span>
        <span class="n">start_pos</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">weights_info</span><span class="p">):</span>
            <span class="n">end_pos</span> <span class="o">=</span> <span class="n">start_pos</span> <span class="o">+</span> <span class="n">layer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">layer</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">gap</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">6.</span> <span class="o">/</span> <span class="p">(</span><span class="n">layer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">layer</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">ans</span><span class="p">[</span><span class="n">start_pos</span><span class="p">:</span><span class="n">end_pos</span><span class="p">]</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="n">gap</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">gap</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">w_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">start_pos</span> <span class="o">=</span> <span class="n">end_pos</span> 
        <span class="k">return</span> <span class="n">ans</span>
    
    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
   
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_layers</span><span class="p">)</span>  <span class="c"># Copy</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_info</span> <span class="o">=</span> <span class="p">[(</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">layers</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">opti_options</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">opti_options</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rand_init</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_info</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnd</span><span class="p">)</span>

        <span class="c"># Unpack the weights and assign them to the layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">start_pos</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">w_info</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_info</span><span class="p">:</span>
            <span class="n">end_pos</span> <span class="o">=</span> <span class="n">start_pos</span> <span class="o">+</span> <span class="n">w_info</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">w_info</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="n">start_pos</span><span class="p">:</span><span class="n">end_pos</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">w_info</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">w_info</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">SigmoidLayer</span><span class="p">(</span><span class="n">W</span><span class="o">=</span><span class="n">weight</span><span class="p">))</span>
            <span class="n">start_pos</span> <span class="o">=</span> <span class="n">end_pos</span>
        
        <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_info</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)))</span>
        <span class="n">MinibatchOpti</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">cost_prime</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">opti_method</span><span class="p">,</span>
                               <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rnd</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">maxiter</span><span class="p">,</span> 
                               <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">opti_options</span><span class="p">,</span>
                               <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">callback</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h2 class="ipynb">
  MNINST
</h2>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lets see how it good it does the using the MINST dataset: 50k rows for training and 10k validations, 748 features.</p>
<p>For all the optimization algorithms I am going to use 100 iterations using a batch size of 100. Also I only timed the fitting once because it takes a long time and I am lazy, also the difference between iterations when the times are that long are not that significant.</p>
<p>My setup is: Macbook Pro 2.5 GHz Inter Core i5. 16 GB RAM.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="kn">import</span> <span class="nn">cPickle</span><span class="o">,</span> <span class="nn">gzip</span><span class="o">,</span> <span class="nn">numpy</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s">&#39;mnist.pkl.gz&#39;</span><span class="p">,</span> <span class="s">&#39;rb&#39;</span><span class="p">)</span>
<span class="n">train_set</span><span class="p">,</span> <span class="n">valid_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="n">cPickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">valid_set</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">valid_set</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
</pre></div>

</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3 class="ipynb">
  Gradient decent
</h3>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>First let's try using a simple gradient decent, the bad part is that one needs to input that <a href="http://arxiv.org/abs/1206.1106">pesky learning rate</a>.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="n">options</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">options</span><span class="p">[</span><span class="s">&#39;learning_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">options</span><span class="p">[</span><span class="s">&#39;learning_rate_decay&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="n">nn</span> <span class="o">=</span> <span class="n">NN</span><span class="p">([</span><span class="mi">25</span><span class="p">],</span> <span class="n">opti_method</span><span class="o">=</span><span class="s">&#39;GD&#39;</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">opti_options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="o">%</span><span class="k">timeit</span> <span class="o">-</span><span class="n">n1</span> <span class="o">-</span><span class="n">r1</span> <span class="n">nn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
<div class="vbox output_wrapper">
<div class="output vbox">
<div class="hbox output_area">
<div class="prompt output_prompt"></div>
<div class="output_subarea output_stream output_stdout">
<pre class="ipynb">Maximum number of iterations reached
1 loops, best of 1: 284 s per loop
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="n">accuracy_score</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">),</span> <span class="n">y_valid</span><span class="p">)</span>
</pre></div>

</div>
</div>
<div class="vbox output_wrapper">
<div class="output vbox">
<div class="hbox output_area">
<div class="prompt output_prompt">Out[17]:</div>
<div class="output_subarea output_pyout">
<pre class="ipynb">0.83160000000000001</pre>
</div>
</div>
</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3 class="ipynb">
  RMSPROP
</h3>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>To remove the learning rate an easy solution is to use RMSPROP.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="n">options</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">options</span><span class="p">[</span><span class="s">&#39;decay&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.9</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="n">nn</span> <span class="o">=</span> <span class="n">NN</span><span class="p">([</span><span class="mi">25</span><span class="p">],</span> <span class="n">opti_method</span><span class="o">=</span><span class="s">&#39;RMSPROP&#39;</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">opti_options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="o">%</span><span class="k">timeit</span> <span class="o">-</span><span class="n">n1</span> <span class="o">-</span><span class="n">r1</span> <span class="n">nn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
<div class="vbox output_wrapper">
<div class="output vbox">
<div class="hbox output_area">
<div class="prompt output_prompt"></div>
<div class="output_subarea output_stream output_stdout">
<pre class="ipynb">Maximum number of iterations reached
1 loops, best of 1: 297 s per loop
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="n">accuracy_score</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">),</span> <span class="n">y_valid</span><span class="p">)</span>
</pre></div>

</div>
</div>
<div class="vbox output_wrapper">
<div class="output vbox">
<div class="hbox output_area">
<div class="prompt output_prompt">Out[21]:</div>
<div class="output_subarea output_pyout">
<pre class="ipynb">0.18629999999999999</pre>
</div>
</div>
</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3 class="ipynb">
  Conjugate gradient
</h3>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally my personal favorite is just to use the scipy optimization methods, one has to be careful though because most are for full-batch optimization. But the Conjugate Gradient and L-BFGS-B works on mini-batches. Personally I prefer CG because gave me better results.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="n">options</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">options</span><span class="p">[</span><span class="s">&#39;mb_maxiter&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="n">nn</span> <span class="o">=</span> <span class="n">NN</span><span class="p">([</span><span class="mi">25</span><span class="p">],</span> <span class="n">opti_method</span><span class="o">=</span><span class="s">&#39;CG&#39;</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">opti_options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="o">%</span><span class="k">timeit</span> <span class="o">-</span><span class="n">n1</span> <span class="o">-</span><span class="n">r1</span> <span class="n">nn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
<div class="vbox output_wrapper">
<div class="output vbox">
<div class="hbox output_area">
<div class="prompt output_prompt"></div>
<div class="output_subarea output_stream output_stdout">
<pre class="ipynb">Maximum number of iterations reached
1 loops, best of 1: 349 s per loop
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="n">accuracy_score</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">),</span> <span class="n">y_valid</span><span class="p">)</span>
</pre></div>

</div>
</div>
<div class="vbox output_wrapper">
<div class="output vbox">
<div class="hbox output_area">
<div class="prompt output_prompt">Out[25]:</div>
<div class="output_subarea output_pyout">
<pre class="ipynb">0.86070000000000002</pre>
</div>
</div>
</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3 class="ipynb">
  Comparison
</h3>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's look at the results in a beautiful pandas DataFrame.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="input_area box-flex1">
<div class="highlight-ipynb"><pre class="ipynb"><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([[</span><span class="mi">284</span><span class="p">,</span> <span class="mf">0.8316</span><span class="p">],</span> <span class="p">[</span><span class="mi">297</span><span class="p">,</span> <span class="mf">0.1863</span><span class="p">],</span> <span class="p">[</span><span class="mi">314</span><span class="p">,</span> <span class="mf">0.8607</span><span class="p">]],</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;GD&#39;</span><span class="p">,</span> <span class="s">&#39;RMSPROP&#39;</span><span class="p">,</span> <span class="s">&#39;CG&#39;</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;Time [s]&#39;</span><span class="p">,</span> <span class="s">&#39;Accuracy&#39;</span><span class="p">])</span>
</pre></div>

</div>
</div>
<div class="vbox output_wrapper">
<div class="output vbox">
<div class="hbox output_area">
<div class="prompt output_prompt">Out[27]:</div>
<div class="output_subarea output_pyout output_html rendered_html">
<div style="max-height:1000px;max-width:540px;overflow:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time [s]</th>
      <th>Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>GD</th>
      <td> 284</td>
      <td> 0.8316</td>
    </tr>
    <tr>
      <th>RMSPROP</th>
      <td> 297</td>
      <td> 0.1863</td>
    </tr>
    <tr>
      <th>CG</th>
      <td> 314</td>
      <td> 0.8607</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h2 class="ipynb">
  Conclusions
</h2>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Even though gradient decent did well I still prefer the scipy optimization methods, maybe because they are just more robust and don't have a learning rate. It takes more time but is not the end of the world. I don't know what is wrong with my RMSPROP implementation I looked at some implementations online and couldn't found the error, if someone sees anything suspicious let me know.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Some improvements I would love to do and ideas I want to test:</p>
<ol>
<li>Use Numba to speed up the process, in theory having the cost function, its gradient and optimization in different "well" defined functions it should be easy.</li>
<li>Try more optimization methods or why not use an existing implementation because there are many python implementations of these and more algorithms online, just to name a few I found: <a href="https://github.com/amarack/python-rl">python-rl</a> and <a href="https://github.com/BRML/climin">climin</a>.</li>
<li>Do pretraining using RBMs: I am just starting to read about them. </li>
<li>Use minibatches to some point and then switch to bigger minibatches or even full batch optimization.</li>
<li>People suggested me to use a lookup table for the sigmoid. I tried but the accuracy I got was really bad, I have to check that code again.</li>
</ol>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>I have to admit that I cheated a little bit on the post. Because the neural network supports multiple hidden layers but I only used one!
<strong>Why?</strong>: Mainly because it takes a long time to train those networks and I am lazy. Second, I couldn't find a way to make those networks converge without using the scipy advanced optimization methods.</p>
<p>From what I understand the problem are the initial weights, and as a side note I spent almost 2 days trying to find a bug while training the MNIST dataset and it was that I started all the layers weights with similar values. The <a href="http://www.cs.toronto.edu/~gdahl/papers/momentumNesterovDeepLearning.pdf">initial weights are <strong>very</strong> important</a>.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>I think I have learned enough about neural networks for my personal satisfaction, so this is probably the last iteration of my Neural network. I will definitely keep looking at the updates of NN research but not as almost fulltime as I been doing the past weeks. Is an imposible mission to catch up that amount of information in my free time. Having spent almost a month reading about NN my (obvious) conclusion is that researchers are just scratching the surface of what is possible, and the next years are going to be exciting.</p>
<p>If you are looking for a more complete implementation of a deep belif network there is free <a href="http://www.cs.toronto.edu/~gdahl/">python (gpu) implementation</a> by one person on Geoffrey Hinton group which I haven't look but seams promising and hopefully he will release more code. </p>
</div></div>
        </div>
    </article>

    <div class="metadata">
        <ul>
            <li>
                <strong>Published:</strong>
                <i><time datetime="2013-07-27T00:00:00">27.07.2013</time></i>
            </li>
            <li>
                <strong>In:</strong>
                <a href="http://danielfrg.github.io/category/machine-learning.html">Machine learning</a>
            </li>
                        <li>
                <strong>Tags:</strong>
                <a href="http://danielfrg.github.io/tag/python.html">python</a> 
                <a href="http://danielfrg.github.io/tag/machine-learning.html">machine learning</a> 
                <a href="http://danielfrg.github.io/tag/neural-networks.html">neural networks</a> 
                            </li>
                        <li>
                <strong>Written by:</strong>
                <a href="http://danielfrg.github.io/author/daniel-rodriguez.html">Daniel Rodriguez</a>
            </li>
        </ul>
    </div>
</div>
        </div>

        <footer>
            <section class='footer'>
    <div class="post social container row-fluid">
        <div class="span3">
            <div class="fb-like" data-send="false" data-layout="button_count" data-show-faces="false"></div>
        </div>
        <div class="span3">
            <a href="https://twitter.com/share" class="twitter-share-button" data-via="danielfrg">Tweet</a>
        </div>

        <div class="span3">
            <div class="g-plusone" data-size="medium" data-annotation="bubble"></div>
        </div>

        <div class="span3 hn">
            <span id="hnews"></span>
        </div>
    </div>

    <div id="disqus_thread" class="comments container"></div>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>

<script src="/theme/js/social.js"></script>
        </footer>


        <script type="text/javascript">
        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-35523657-2']);
        _gaq.push(['_trackPageview']);

        (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
        })();
        </script>
    </body>
</html>