<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <meta name="author" content="Daniel Rodriguez">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width">
        <title>word2vec in yhat: Word vector similarity | Daniel Rodriguez</title>

        <link rel="alternate" type="application/atom+xml" title="Daniel Rodriguez blog atom feed" href="/feeds/all.atom.xml" />
        <link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700' rel='stylesheet' type='text/css'>

        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
        <link rel="stylesheet" href="/theme/css/pygments.css">
        <link rel="stylesheet" href="/theme/css/main.css">

<script src="//ajax.googleapis.com/ajax/libs/angularjs/1.0.7/angular.min.js"></script>
<script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
    </head>

    <body>
        <header class="navbar navbar-static-top bs-docs-nav main-header">
            <div class="container">
                <div class="navbar-header">
                    <a class="navbar-brand" href="/" title="Home" class="title">Daniel Rodriguez</a></li>
                </div>
                <nav class="collapse navbar-collapse bs-navbar-collapse" role="navigation">
                    <ul class="nav navbar-nav navbar-right">
                            <li><a href="/pages/about.html" title="About">About</a></li>
                            <li><a href="http://github.com/danielfrg" title="danielfrg's Github" rel="me">Github</a></li>
                            <li><a href="http://twitter.com/danielfrg" title="danielfrg Twitter" rel="me">Twitter</a></li>
                            <li><a href="/archives.html" title="Archive">Archive</a></li>
                            <li><a href="/feeds/all.atom.xml" title="danielfrg.github.io RSS feed" rel="me">RSS</a></li>
                    </ul>
                </nav>
            </div>
        </header>

<div class="container post">

    <article>
        <header>
            <h1>word2vec in yhat: Word vector similarity</h1>
            <time datetime="article.date.isoformat()" pubdate>September 21, 2013</time>
        </header>

        <div class="article_content">
            <p>A <a href="http://google-opensource.blogspot.com/2013/08/learning-meaning-behind-words.html">few weeks ago</a>
Google released some code to convert words to vectors called
<a href="https://code.google.com/p/word2vec/">word2vec</a>.
The company I am currently working on does something similar and I was quite amazed by the performance
and accuracy of Google's algorithm so I created a simple python wrapper to call the C code for training
and read the training vectors into numpy arrays, you can check it out on
<a href="https://pypi.python.org/pypi/word2vec">pypi (word2vec)</a>.</p>
<p>At the same time I found out about <a href="http://yhathq.com/">yhat</a>, I found about them
via twitter and after reading their blog I had to try their product. What they do is very simple
but very useful: take some python (scikit-learn) or R classifier and create a REST
endpoint to make predictions on new data. The product is still in very beta but the guys were
very responsive and they helped me to solve some of my issues.</p>
<p>The only restriction I had is the yhat limit for free accounts is 50 Mgs per classifier which on this
particular case is not enough so I had to reduce the vector size to 25 from the default (100).
And reduce it to only 70k vectors, so the results in the app below are a little limited, but the results
are very similar.</p>
<h2>Training</h2>
<p>Using my <a href="https://pypi.python.org/pypi/word2vec">word2vec wrapper</a> is as simple as download and unzip the text8 <a href="http://mattmahoney.net/dc/text8.zip">(link)</a> file and:</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">word2vec</span> <span class="kn">import</span> <span class="n">word2vec</span>
<span class="n">word2vec</span><span class="p">(</span><span class="s">&#39;text8&#39;</span><span class="p">,</span> <span class="s">&#39;text8-25.vec&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
</pre></div>


<p>This created a file (<code>text8-25.vec</code>) with the vectors that can be loaded into numpy. Again using my <a href="https://pypi.python.org/pypi/word2vec">word2vec wrapper</a> is really simple:</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">word2vec</span> <span class="kn">import</span> <span class="n">WordVectors</span>
<span class="n">vectors</span> <span class="o">=</span> <span class="n">WordVectors</span><span class="p">(</span><span class="s">&#39;text8-31.vec&#39;</span><span class="p">)</span>
</pre></div>


<h2>Yhat</h2>
<p>Then just need to create a yhat model and in the <code>predict</code> method calculate the distance between the vectors.
That code is also included on my word2vec package using scipy cosine distance (<a href="http://nbviewer.ipython.org/urls/raw.github.com/danielfrg/word2vec/master/examples/demo-word.ipynb">example</a>),
on this case I just used the numpy <code>linalg.norm</code>.</p>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">yhat</span> <span class="kn">import</span> <span class="n">BaseModel</span>

<span class="k">class</span> <span class="nc">Word2VecCLF</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">request</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">request</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">request</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39; Calculate distances</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">request</span><span class="p">[</span><span class="s">&#39;word&#39;</span><span class="p">]</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">request</span><span class="p">[</span><span class="s">&#39;n&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="s">&#39;n&#39;</span> <span class="ow">in</span> <span class="n">request</span> <span class="k">else</span> <span class="mi">10</span>

        <span class="n">distances</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e6</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
        <span class="n">values</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>

        <span class="n">words</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">words</span>
        <span class="n">vectors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectors</span>

        <span class="n">target_ix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">words</span> <span class="o">==</span> <span class="n">target</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">vector</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">vectors</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">word</span> <span class="o">!=</span> <span class="n">target</span><span class="p">:</span>
                <span class="n">n_dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">vectors</span><span class="p">[</span><span class="n">target_ix</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">vector</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">n_dist</span> <span class="o">&lt;</span> <span class="nb">max</span><span class="p">(</span><span class="n">distances</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">n_dist</span> <span class="o">&lt;</span> <span class="nb">min</span><span class="p">(</span><span class="n">distances</span><span class="p">):</span>
                        <span class="n">distances</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_dist</span><span class="p">)</span>
                        <span class="n">distances</span> <span class="o">=</span> <span class="n">distances</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span>
                        <span class="n">values</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">word</span><span class="p">)</span>
                        <span class="n">values</span> <span class="o">=</span> <span class="n">values</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dist_1</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">distances</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])):</span>
                            <span class="n">dist_2</span> <span class="o">=</span> <span class="n">distances</span><span class="p">[</span><span class="n">n</span> <span class="o">-</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
                            <span class="k">if</span> <span class="n">n_dist</span> <span class="o">&lt;</span> <span class="n">dist_2</span> <span class="ow">and</span> <span class="n">n_dist</span> <span class="o">&gt;=</span> <span class="n">dist_1</span><span class="p">:</span>
                                <span class="n">distances</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_dist</span><span class="p">)</span>
                                <span class="n">distances</span> <span class="o">=</span> <span class="n">distances</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span>
                                <span class="n">values</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">word</span><span class="p">)</span>
                                <span class="n">values</span> <span class="o">=</span> <span class="n">values</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span>
                                <span class="k">break</span>
        <span class="k">return</span> <span class="p">{</span><span class="s">&#39;distances&#39;</span><span class="p">:</span> <span class="n">distances</span><span class="p">,</span> <span class="s">&#39;words&#39;</span><span class="p">:</span> <span class="n">values</span><span class="p">}</span>
</pre></div>


<p>Then just need to upload to yhat.</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">yhat</span> <span class="kn">import</span> <span class="n">Yhat</span>
<span class="n">yh</span> <span class="o">=</span> <span class="n">Yhat</span><span class="p">(</span><span class="s">&quot;EMAIL&quot;</span><span class="p">,</span> <span class="s">&quot;TOKEN&quot;</span><span class="p">)</span>
<span class="n">yh</span><span class="o">.</span><span class="n">deploy</span><span class="p">(</span><span class="s">&quot;word2vec&quot;</span><span class="p">,</span> <span class="n">word2vec_clf</span><span class="p">)</span>
</pre></div>


<p>If everything goes fine you have a REST endpoint you can call.</p>
<p><a id="example"></a></p>
<h2>Example</h2>
<p>I built a simple app using <a href="http://angularjs.org/">angularJS</a>.
Just type any word and the number of close word vectors you want and click the button.
On the list that it generates you can click on any word and it will give you the neighbors for that word.</p>
<div ng-app="app">
    <div ng-controller="MainCtrl">
        <form class="form-inline" role="form" style="max-width: 550px; margin: 0 auto;">
            <div class="form-group">
                <input type="text" class="form-control" ng-model="form_word" placeholder="a word">
            </div>
            <div class="form-group">
                <input type="number" class="form-control" ng-model="form_n">
            </div>
            <button class="btn btn-default" ng-click="formRequest()">Request</button>
        </form>

        <table class="table" style="max-width: 350px; margin: 0 auto;">
            <thead>
                <tr>
                    <th>word</th>
                    <th>distance</th>
                </tr>
            </thead>
            <tr ng-repeat="word in words">
                <td><a href="#example" ng-click="listRequest(word.word)" eat-click>{{word.word}}</a></td>
                <td>{{word.distance}}</td>
            </tr>
        </table>
    </div>

</div>

<script type="text/javascript">

var app = angular.module('app', []);

app.directive('eatClick', function() {
    return function(scope, element, attrs) {
        $(element).click(function(event) {
            event.preventDefault();
        });
    }
})

var MainCtrl = function($scope, $http) {
    $scope.form_word = '';
    $scope.form_n = 10;
    $scope.words = [];

    $scope.formRequest = function() {
        $scope.request($scope.form_word, $scope.form_n);
    }

    $scope.listRequest = function(word) {
        $scope.request(word, $scope.form_n);
    }

    $scope.request = function(word, n) {
        var BASE_URL = 'http://cors.io/api.yhathq.com/predict?username=df.rodriguez143%40gmail.com&model=word2vec&apikey=5162184b820a6ac92274bec2e98b8c88&version=23';
        var data = {"data": {"word": word, "n": n} }

        $http.post(BASE_URL, data)
            .success(function (data, status, headers, config) {
                $scope.words = [];

                for (var i = 0; i < data.prediction.words.length; i++) {
                    $scope.words.push({"word": data.prediction.words[i],
                                       "distance": data.prediction.distances[i]});
                }
            }).error(function (data, status, headers, config) {
                console.log(data);
            });
    }
}

</script>

<h2>Conclusions</h2>
<p>Definitely some interesting new technologies and tools to keep and eye on. Thanks to Google for
open sourcing the code and thanks to yhat for a good product. I had to do something similar a few
weeks ago and my solution was to use ZMQ to connect the rest endpoint with the actual
classifier yhat makes that possible in 5% of the time.</p>
<p><strong>Found some interesting relations?</strong> Let me know in the comments below.</p>
        </div>

        <div class="meta">
            <div>
                    <a href="/tag/python.html" class="tag">Python</a>
                    <a href="/tag/word2vec.html" class="tag">word2vec</a>
                    <a href="/tag/yhat.html" class="tag">YHat</a>
                    <a href="/tag/machine-learning.html" class="tag">Machine learning</a>
            </div>
            <div>
                <a id="comments-button" class="comments_btn" href="#disqus_thread">Show comments</a>
            </div>
        </div>
    </article>
</div>

<script type="text/javascript">
(function () {
    'use strict';

    // Global object
    var App = {};

    // Create button
    App.commentsButton = document.getElementById('comments-button');

    App.commentsButton.onclick = function () {
        // Remove button action on click
        App.commentsButton.onclick = function () {
        }

        // Create comments container
        App.disqusContainer = document.createElement('div');
        App.disqusContainer.setAttribute('id', 'disqus_thread');
        // App.disqusContainer.setAttribute('class', 'container');

        // Append container to body or div
        // document.body.appendChild( App.disqusContainer );
        var container = document.getElementsByClassName('container post')[0];
        container.appendChild(App.disqusContainer);

        // Your Disqus shortname
        App.disqus_shortname = 'danielfrg';

        // Embed Disqus
        var dsq = document.createElement('script');

        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + App.disqus_shortname + '.disqus.com/embed.js';

        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);

        window.scrollTo(0, dsq.offsetTop - 200);
    };
})();
</script>

        <style type="text/css">.text_cell .prompt {
    display: none;
}

div.cell {
    padding: 0;
}

div.text_cell_render {
    padding: 0;
}

div.prompt {
    font-size: 13px;
}

div.input_prompt {
    padding: .7em 0.2em;
}

div.output_prompt {
    padding: .4em .2em;
}

div.input_area {
    margin: .2em 0.4em;
}

table.dataframe {
    font-family: Arial, sans-serif;
    font-size: 13px;
    line-height: 20px;
}

table.dataframe th, td {
    padding: 4px;
    text-align: left;
}</style>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-35523657-2', 'danielfrg.com');
  ga('send', 'pageview');

</script>

    </body>
</html>